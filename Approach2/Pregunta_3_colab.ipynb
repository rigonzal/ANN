{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pregunta 3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rigonzal/ANN/blob/master/Approach2/Pregunta_3_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "PK_ABewqRtDE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# INF-395 Redes Neuronales Artificiales II-2018\n",
        "\n",
        "## Tarea 2 - Redes Convolucionales y sus aplicaciones\n",
        "\n",
        "\n",
        "26/11/2018\n",
        "\n",
        "* Rodrigo González Smith 201303026-2\n",
        "* Ignacio Valenzuela Albornoz 2014073055-1"
      ]
    },
    {
      "metadata": {
        "id": "4K43-BS1SZ3i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Introducción Parte 3\n",
        "\n",
        "\n",
        "\n",
        "Débido al tema del trabajo usaremos **Keras** para la creación de las redes y su posterior entrenamiento/validación. Como también las librerías comunes de trabajo de Python que nos facilitarán nuestras tareas experimentales:"
      ]
    },
    {
      "metadata": {
        "id": "K2QZFu6VShhH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Correr solo en Colab\n",
        "!pip install -q keras\n",
        "!pip install -q nltk\n",
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xMvEleO7Smal",
        "colab_type": "code",
        "outputId": "e9098327-78d9-45e5-ffc6-083c9b456404",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np   \n",
        "import os, re, sys\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import WordNetLemmatizer\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import SGD, rmsprop\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.models import model_from_json\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import h5py\n",
        "import nltk\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4Ez5mEPQSpX-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## 1) CNN sobre texto\n",
        "\n",
        "Ahora usaremos redes neuronales convolucionales para (NLP), es decir, procesamiento de Lenguaje Natural. El dataset cuenta con miles de avisos de trabajo, y el objetivo es a partir de estos poder predecir el salario asociado. Como bien dice el [sitio oficial](https://www.kaggle.com/c/job-salary-prediction)  que entrega el dataset, es crear un *Salary prediction engine*. "
      ]
    },
    {
      "metadata": {
        "id": "zukfqz3yl8L3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Primero que todos haremos una conexión con el google drive para poder importar los archivos directamente desde allí y acelerar el proceso de carga de datos."
      ]
    },
    {
      "metadata": {
        "id": "Xcc3HZeMl6Ek",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5CAt-CF8maMz",
        "colab_type": "code",
        "outputId": "bf939d43-fc18-4c94-da5d-d28fffe6d63f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "file_list = drive.ListFile().GetList()  # Analizamos el contenido del Drive para obtener el id del archivo\n",
        "for file in file_list:\n",
        "  if(file['title'] == 'Train_rev1.csv' or 'Val' in file['title'] ):\n",
        "    print('title {}, id {}'.format(file['title'], file['id']))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title Train_rev1.csv, id 1K--wMccLW0eHdVrp8RXe3c-bXPfLNPxo\n",
            "title Train_rev1.csv, id 1bIyTdMaZn5h0EP0eNFmkFpblI0mBTT-O\n",
            "title Valid_rev1.csv, id 1NFYbS6ulPjdjQJRK5ixEE7rT9bQ7zNKN\n",
            "title CV-Ignacio-Valenzuela.pdf, id 1cicPdaP4SpPmc9UQ8BPFQ_Shg9YFXiqz\n",
            "title Ignacio Valenzuela, id 0B_SDEfD2s3nUVDF2YThQNFV5S3c\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rHzGlOu_oIuN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "download_path = os.path.expanduser('~/data') # Luego creamos un directorio local para almacenar la data\n",
        "try:\n",
        "  os.makedirs(download_path)\n",
        "except FileExistsError:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S_MCWcIRoVBs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_file = os.path.join(download_path, 'Train_rev1.csv') # Luego importamos la informacion\n",
        "\n",
        "temp_file = drive.CreateFile({'id': '1K--wMccLW0eHdVrp8RXe3c-bXPfLNPxo'})\n",
        "temp_file.GetContentFile(output_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zO4PbPiYfto5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(output_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6WiebzGto6ml",
        "colab_type": "code",
        "outputId": "dc984b39-3a60-4e60-ed6d-1b94c38ba169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>FullDescription</th>\n",
              "      <th>LocationRaw</th>\n",
              "      <th>LocationNormalized</th>\n",
              "      <th>ContractType</th>\n",
              "      <th>ContractTime</th>\n",
              "      <th>Company</th>\n",
              "      <th>Category</th>\n",
              "      <th>SalaryRaw</th>\n",
              "      <th>SalaryNormalized</th>\n",
              "      <th>SourceName</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12612628</td>\n",
              "      <td>Engineering Systems Analyst</td>\n",
              "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
              "      <td>Dorking, Surrey, Surrey</td>\n",
              "      <td>Dorking</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Gregory Martin International</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>20000 - 30000/annum 20-30K</td>\n",
              "      <td>25000</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12612830</td>\n",
              "      <td>Stress Engineer Glasgow</td>\n",
              "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
              "      <td>Glasgow, Scotland, Scotland</td>\n",
              "      <td>Glasgow</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Gregory Martin International</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>25000 - 35000/annum 25-35K</td>\n",
              "      <td>30000</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12612844</td>\n",
              "      <td>Modelling and simulation analyst</td>\n",
              "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
              "      <td>Hampshire, South East, South East</td>\n",
              "      <td>Hampshire</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Gregory Martin International</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>20000 - 40000/annum 20-40K</td>\n",
              "      <td>30000</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12613049</td>\n",
              "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
              "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
              "      <td>Surrey, South East, South East</td>\n",
              "      <td>Surrey</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Gregory Martin International</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>25000 - 30000/annum 25K-30K negotiable</td>\n",
              "      <td>27500</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12613647</td>\n",
              "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
              "      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n",
              "      <td>Surrey, South East, South East</td>\n",
              "      <td>Surrey</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Gregory Martin International</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>20000 - 30000/annum 20-30K</td>\n",
              "      <td>25000</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Id                                              Title  \\\n",
              "0  12612628                        Engineering Systems Analyst   \n",
              "1  12612830                            Stress Engineer Glasgow   \n",
              "2  12612844                   Modelling and simulation analyst   \n",
              "3  12613049  Engineering Systems Analyst / Mathematical Mod...   \n",
              "4  12613647         Pioneer, Miser Engineering Systems Analyst   \n",
              "\n",
              "                                     FullDescription  \\\n",
              "0  Engineering Systems Analyst Dorking Surrey Sal...   \n",
              "1  Stress Engineer Glasgow Salary **** to **** We...   \n",
              "2  Mathematical Modeller / Simulation Analyst / O...   \n",
              "3  Engineering Systems Analyst / Mathematical Mod...   \n",
              "4  Pioneer, Miser  Engineering Systems Analyst Do...   \n",
              "\n",
              "                         LocationRaw LocationNormalized ContractType  \\\n",
              "0            Dorking, Surrey, Surrey            Dorking          NaN   \n",
              "1        Glasgow, Scotland, Scotland            Glasgow          NaN   \n",
              "2  Hampshire, South East, South East          Hampshire          NaN   \n",
              "3     Surrey, South East, South East             Surrey          NaN   \n",
              "4     Surrey, South East, South East             Surrey          NaN   \n",
              "\n",
              "  ContractTime                       Company          Category  \\\n",
              "0    permanent  Gregory Martin International  Engineering Jobs   \n",
              "1    permanent  Gregory Martin International  Engineering Jobs   \n",
              "2    permanent  Gregory Martin International  Engineering Jobs   \n",
              "3    permanent  Gregory Martin International  Engineering Jobs   \n",
              "4    permanent  Gregory Martin International  Engineering Jobs   \n",
              "\n",
              "                                SalaryRaw  SalaryNormalized        SourceName  \n",
              "0              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  \n",
              "1              25000 - 35000/annum 25-35K             30000  cv-library.co.uk  \n",
              "2              20000 - 40000/annum 20-40K             30000  cv-library.co.uk  \n",
              "3  25000 - 30000/annum 25K-30K negotiable             27500  cv-library.co.uk  \n",
              "4              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "xEqm8rEYo-5s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Con el código anterior, se logró cargar el dataset a pandas en un tiempo muy corto. Este procedimiento permite una carga de datos directamente desde GoogleDrive, y como Colab trabaja dentro de ese entorno, el procedimiento es simple y rápido."
      ]
    },
    {
      "metadata": {
        "id": "pz5oRrLVq0th",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ahora se implementará una función la cual preprocesará la información. Primero se dejarán todas las palabras en minúscula, luego gracias a funciones regulares quitaremos ciertos patrones de los anuncios (que estan dentro de la columna \"FullDescription\") el analiza la presencia de números y otros símbolos reemplazandolo por un espacio en blanco. Luego se aplica a la eliminación de stopwords aplicación de lemmatization. Luego se guarda el dato procesado y se actualiza la columna dentro del dataset ya que esta será la que ocuparemos para realizar el split de los datos."
      ]
    },
    {
      "metadata": {
        "id": "lr4i-0mPbB2e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stoplist = set(stopwords.words('english'))\n",
        "\n",
        "def pre_procesar(df):\n",
        "    #preprocesar texto de los anuncios\n",
        "    #Eliminación de stopwords, stemming/lemmatization, puntuación, etc\n",
        "    df_procesado = {}\n",
        "    for column in df.columns:\n",
        "      columna = list()\n",
        "      for s in df[column]:\n",
        "        s= s.lower()\n",
        "        s= re.sub(r'[^\\w]', ' ',s)\n",
        "        s= re.sub(r'\\b[a-z]\\b', ' ',  s)\n",
        "        s= re.sub(r'\\b[a-z][a-z]\\b', ' ',  s)\n",
        "        s=re.sub(r'\\b[0-9]\\b', ' ',  s)\n",
        "        s=re.sub(r'\\b[0-9][0-9]\\b', ' ',  s)\n",
        "        s=re.sub(r'\\b[0-9][0-9][0-9]\\b', ' ',  s)\n",
        "        s= re.sub(r'[^\\w.]', ' ', s)\n",
        "        s= list(s.split())\n",
        "        s= [word for word in s if not word in stoplist]\n",
        "        s= [nltk.WordNetLemmatizer().lemmatize(word) for word in s]\n",
        "        columna.append(' '.join(s))\n",
        "      df_procesado[column] = columna\n",
        "    return pd.DataFrame(df_procesado)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sjIitBWSGx6U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Después de hacer el resumen del dataset, vemos que posee variables con valor NaN. Estos no son strings, si no que valores int, por lo que aplicar ciertas funciones de preprocesamiento no podrán aplicarse por formato erróneo. Para eso, todas las variables que posean NaN las pasaremos a un string \"nan\", para que así no hayan problemas de formato."
      ]
    },
    {
      "metadata": {
        "id": "yC1KGSzHfsnz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_dataframe=data['SalaryNormalized'].values\n",
        "x_dataframe=data.drop(columns=['SalaryNormalized', 'SalaryRaw', 'Id'])\n",
        "\n",
        "x_dataframe.loc[x_dataframe['ContractType'].isna(), 'ContractType'] = 'nan'\n",
        "x_dataframe.loc[x_dataframe['ContractTime'].isna(), 'ContractTime'] = 'nan'\n",
        "x_dataframe.loc[x_dataframe['Company'].isna(), 'Company'] = 'nan'\n",
        "x_dataframe.loc[x_dataframe['Title'].isna(), 'Title'] = ''\n",
        "x_dataframe.loc[x_dataframe['SourceName'].isna(), 'SourceName'] = 'nan'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0siX-EkJL40Q",
        "colab_type": "code",
        "outputId": "1985e3eb-ed61-4ecb-a656-9f385aece9f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "cell_type": "code",
      "source": [
        "x_dataframe.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>FullDescription</th>\n",
              "      <th>LocationRaw</th>\n",
              "      <th>LocationNormalized</th>\n",
              "      <th>ContractType</th>\n",
              "      <th>ContractTime</th>\n",
              "      <th>Company</th>\n",
              "      <th>Category</th>\n",
              "      <th>SourceName</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Engineering Systems Analyst</td>\n",
              "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
              "      <td>Dorking, Surrey, Surrey</td>\n",
              "      <td>Dorking</td>\n",
              "      <td>nan</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Gregory Martin International</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Stress Engineer Glasgow</td>\n",
              "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
              "      <td>Glasgow, Scotland, Scotland</td>\n",
              "      <td>Glasgow</td>\n",
              "      <td>nan</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Gregory Martin International</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Modelling and simulation analyst</td>\n",
              "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
              "      <td>Hampshire, South East, South East</td>\n",
              "      <td>Hampshire</td>\n",
              "      <td>nan</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Gregory Martin International</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
              "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
              "      <td>Surrey, South East, South East</td>\n",
              "      <td>Surrey</td>\n",
              "      <td>nan</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Gregory Martin International</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
              "      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n",
              "      <td>Surrey, South East, South East</td>\n",
              "      <td>Surrey</td>\n",
              "      <td>nan</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Gregory Martin International</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Title  \\\n",
              "0                        Engineering Systems Analyst   \n",
              "1                            Stress Engineer Glasgow   \n",
              "2                   Modelling and simulation analyst   \n",
              "3  Engineering Systems Analyst / Mathematical Mod...   \n",
              "4         Pioneer, Miser Engineering Systems Analyst   \n",
              "\n",
              "                                     FullDescription  \\\n",
              "0  Engineering Systems Analyst Dorking Surrey Sal...   \n",
              "1  Stress Engineer Glasgow Salary **** to **** We...   \n",
              "2  Mathematical Modeller / Simulation Analyst / O...   \n",
              "3  Engineering Systems Analyst / Mathematical Mod...   \n",
              "4  Pioneer, Miser  Engineering Systems Analyst Do...   \n",
              "\n",
              "                         LocationRaw LocationNormalized ContractType  \\\n",
              "0            Dorking, Surrey, Surrey            Dorking          nan   \n",
              "1        Glasgow, Scotland, Scotland            Glasgow          nan   \n",
              "2  Hampshire, South East, South East          Hampshire          nan   \n",
              "3     Surrey, South East, South East             Surrey          nan   \n",
              "4     Surrey, South East, South East             Surrey          nan   \n",
              "\n",
              "  ContractTime                       Company          Category  \\\n",
              "0    permanent  Gregory Martin International  Engineering Jobs   \n",
              "1    permanent  Gregory Martin International  Engineering Jobs   \n",
              "2    permanent  Gregory Martin International  Engineering Jobs   \n",
              "3    permanent  Gregory Martin International  Engineering Jobs   \n",
              "4    permanent  Gregory Martin International  Engineering Jobs   \n",
              "\n",
              "         SourceName  \n",
              "0  cv-library.co.uk  \n",
              "1  cv-library.co.uk  \n",
              "2  cv-library.co.uk  \n",
              "3  cv-library.co.uk  \n",
              "4  cv-library.co.uk  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "hJTswrzSITxf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Luego de esto, usamos la función que preprocesa el texto y posteriormente realizamos un split de la informacion para crear set de entrenamiento, validación y testeo."
      ]
    },
    {
      "metadata": {
        "id": "hTvefufQCiBK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_procesado = pre_procesar(x_dataframe)\n",
        "k=len(df_procesado)\n",
        "y_train = y_dataframe[0:int(k*0.70)]\n",
        "y_val = y_dataframe[int(k*0.70):int(k*0.85)]\n",
        "x_train=df_procesado[0:int(k*0.70)] #70% training\n",
        "x_val=df_procesado[int(k*0.70):int(k*0.85)] #15% validation\n",
        "x_test=df_procesado[int(k*0.85):] #15% test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kPAFgPYsFKAd",
        "colab_type": "code",
        "outputId": "e854e09d-89b5-40cb-9f24-b1aaf665cc7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "cell_type": "code",
      "source": [
        "df_procesado.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Company</th>\n",
              "      <th>ContractTime</th>\n",
              "      <th>ContractType</th>\n",
              "      <th>FullDescription</th>\n",
              "      <th>LocationNormalized</th>\n",
              "      <th>LocationRaw</th>\n",
              "      <th>SourceName</th>\n",
              "      <th>Title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>engineering job</td>\n",
              "      <td>gregory martin international</td>\n",
              "      <td>permanent</td>\n",
              "      <td>nan</td>\n",
              "      <td>engineering system analyst dorking surrey sala...</td>\n",
              "      <td>dorking</td>\n",
              "      <td>dorking surrey surrey</td>\n",
              "      <td>library</td>\n",
              "      <td>engineering system analyst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>engineering job</td>\n",
              "      <td>gregory martin international</td>\n",
              "      <td>permanent</td>\n",
              "      <td>nan</td>\n",
              "      <td>stress engineer glasgow salary currently looki...</td>\n",
              "      <td>glasgow</td>\n",
              "      <td>glasgow scotland scotland</td>\n",
              "      <td>library</td>\n",
              "      <td>stress engineer glasgow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>engineering job</td>\n",
              "      <td>gregory martin international</td>\n",
              "      <td>permanent</td>\n",
              "      <td>nan</td>\n",
              "      <td>mathematical modeller simulation analyst opera...</td>\n",
              "      <td>hampshire</td>\n",
              "      <td>hampshire south east south east</td>\n",
              "      <td>library</td>\n",
              "      <td>modelling simulation analyst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>engineering job</td>\n",
              "      <td>gregory martin international</td>\n",
              "      <td>permanent</td>\n",
              "      <td>nan</td>\n",
              "      <td>engineering system analyst mathematical modell...</td>\n",
              "      <td>surrey</td>\n",
              "      <td>surrey south east south east</td>\n",
              "      <td>library</td>\n",
              "      <td>engineering system analyst mathematical modeller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>engineering job</td>\n",
              "      <td>gregory martin international</td>\n",
              "      <td>permanent</td>\n",
              "      <td>nan</td>\n",
              "      <td>pioneer miser engineering system analyst dorki...</td>\n",
              "      <td>surrey</td>\n",
              "      <td>surrey south east south east</td>\n",
              "      <td>library</td>\n",
              "      <td>pioneer miser engineering system analyst</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Category                       Company ContractTime ContractType  \\\n",
              "0  engineering job  gregory martin international    permanent          nan   \n",
              "1  engineering job  gregory martin international    permanent          nan   \n",
              "2  engineering job  gregory martin international    permanent          nan   \n",
              "3  engineering job  gregory martin international    permanent          nan   \n",
              "4  engineering job  gregory martin international    permanent          nan   \n",
              "\n",
              "                                     FullDescription LocationNormalized  \\\n",
              "0  engineering system analyst dorking surrey sala...            dorking   \n",
              "1  stress engineer glasgow salary currently looki...            glasgow   \n",
              "2  mathematical modeller simulation analyst opera...          hampshire   \n",
              "3  engineering system analyst mathematical modell...             surrey   \n",
              "4  pioneer miser engineering system analyst dorki...             surrey   \n",
              "\n",
              "                       LocationRaw SourceName  \\\n",
              "0            dorking surrey surrey    library   \n",
              "1        glasgow scotland scotland    library   \n",
              "2  hampshire south east south east    library   \n",
              "3     surrey south east south east    library   \n",
              "4     surrey south east south east    library   \n",
              "\n",
              "                                              Title  \n",
              "0                        engineering system analyst  \n",
              "1                           stress engineer glasgow  \n",
              "2                      modelling simulation analyst  \n",
              "3  engineering system analyst mathematical modeller  \n",
              "4          pioneer miser engineering system analyst  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "ge9sGOtHPQBe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vemos que el dataset procesado almacenó correctamente las palabras, separadas mediante un espacio, así tomamos las palabras mas significativas de cada anuncio y permitirá un mejor análisis del texto. \n",
        "\n",
        "Ahora procederemos a usar embedding con los textos para mapearlos en vectores y así poder implementarlos en un modelo de red convolucional. Eso sí, en vez de crear los vectores propios, implementaremos los del archivo Glove ya que estos fueron creados mediante un entrenamiento de muchos datos, por lo que será un buen modelo a implementar. Cabe destacar que la dimensionalidad que aplica es de 100."
      ]
    },
    {
      "metadata": {
        "id": "gkXLLXvcRVK8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_index=dict()\n",
        "j=0\n",
        "for frase in x_train:\n",
        "    seq=frase.split()\n",
        "    for term in seq:\n",
        "        if term not in word_index.keys():\n",
        "            word_index[term]=j\n",
        "            j+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WFEcQBXdRYcg",
        "colab_type": "code",
        "outputId": "760c318e-e047-4d8f-d9b6-381f7da734fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "for file in file_list:\n",
        "  if('glove' in file['title']):\n",
        "    print('title {}, id {}'.format(file['title'], file['id']))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title glove.6B.100d.txt, id 11oaqviHAKGl281V1PqTxCz-dMThf553W\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hpBlDH4LRkD7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f = os.path.join(download_path, 'glove.6B.100d.txt') # Luego importamos la informacion\n",
        "\n",
        "temp_file = drive.CreateFile({'id': '11oaqviHAKGl281V1PqTxCz-dMThf553W'})\n",
        "temp_file.GetContentFile(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UpBRRx4kSndg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lo anterior es el mismo proceso anterior, donde se busca el archivo, se descarga y se implementa en una variable. Luego, se abre este archivo de texto y se aplica el embedding para formar el índice de vectores."
      ]
    },
    {
      "metadata": {
        "id": "-dQYYlRDR2Sc",
        "colab_type": "code",
        "outputId": "4cc6a500-c8c1-42ff-b69b-daa32fbf7175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "f = open(f)\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Se encontraron %s terminos con sus vectores de embedding.' % len(embeddings_index))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Se encontraron 400000 terminos con sus vectores de embedding.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5e_MIVYwTojV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Luego de eso, se procede a armar la matriz de los vectores."
      ]
    },
    {
      "metadata": {
        "id": "oKVdEZXhSa5l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_vector=100\n",
        "embedding_matrix = np.zeros((len(word_index.keys()), embedding_vector))   #puede probar otra inicialización\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words sin match en Glove, serán vectores de ceros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "weey3cXLTusD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ahora llego el momento de crear un modelo y aplicarlo con estos datos. "
      ]
    },
    {
      "metadata": {
        "id": "9W9I6Y__TJwl",
        "colab_type": "code",
        "outputId": "b8872945-cc5e-46c9-8684-e3c058afaf24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"Definir input para el modelo: \"\"\"\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "\n",
        "x_new_train = [[word_index[word] for word in text.split()] for text in x_train]\n",
        "x_new_val = [[word_index[word] for word in text.split() if word in word_index] for text in x_val]\n",
        "\n",
        "max_input_lenght = 10 #modificar este valor en base a su experimentación\n",
        "Xtrain = sequence.pad_sequences(x_new_train,maxlen=max_input_lenght,padding='post',value=0)\n",
        "Xval = sequence.pad_sequences(x_new_val,maxlen=max_input_lenght,padding='post',value=0)\n",
        "\n",
        "\"\"\"Define model trough Model API in Keras\"\"\"\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "embedding_vector=100\n",
        "embedding_layer = Embedding(input_dim=len(word_index.keys()),output_dim=embedding_vector,weights=[embedding_matrix],\n",
        "                     input_length=max_input_lenght,trainable=False)\n",
        "\n",
        "sequence_input = Input(shape=(max_input_lenght,))\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "cov1= Conv1D(128, 5, activation='relu',padding='same')(embedded_sequences)\n",
        "pool = MaxPooling1D(pool_size=2)(cov1)\n",
        "flat = Flatten()(pool)\n",
        "preds = Dense(1, activation='linear')(flat)\n",
        "model = Model(sequence_input, preds)\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='mse',optimizer='rmsprop',metrics=['acc'])\n",
        "model.fit(Xtrain, y_dataframe, validation_data=(Xval, y_val),epochs=25, batch_size=256)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "embedding_4 (Embedding)      (None, 10, 100)           900       \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 10, 128)           64128     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 5, 128)            0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 640)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 641       \n",
            "=================================================================\n",
            "Total params: 65,669\n",
            "Trainable params: 64,769\n",
            "Non-trainable params: 900\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-5bb83f1368ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    802\u001b[0m             ]\n\u001b[1;32m    803\u001b[0m             \u001b[0;31m# Check that all arrays have the same length.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0mcheck_array_length_consistency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m                 \u001b[0;31m# Additional checks to avoid users mistakenly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_array_length_consistency\u001b[0;34m(inputs, targets, weights)\u001b[0m\n\u001b[1;32m    235\u001b[0m                          \u001b[0;34m'the same number of samples as target arrays. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                          \u001b[0;34m'Found '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' input samples '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                          'and ' + str(list(set_y)[0]) + ' target samples.')\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_w\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         raise ValueError('All sample_weight arrays should have '\n",
            "\u001b[0;31mValueError\u001b[0m: Input arrays should have the same number of samples as target arrays. Found 9 input samples and 244768 target samples."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "CFzjp1Nkbydg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}