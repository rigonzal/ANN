{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pregunta 1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rigonzal/ANN/blob/master/Approach2/Pregunta_1_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "G1CT4yRAUJS4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hxj9xj4WUfKl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2bec887b-ff9c-445c-d4dd-f34df39c185a"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np   \n",
        "import os   \n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import SGD, rmsprop\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.models import model_from_json\n",
        "import os\n",
        "import h5py\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "qYOgL_0ZUyN2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7a6fe8d2-4688-4f45-eff5-d44ac4f7a334"
      },
      "cell_type": "code",
      "source": [
        "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']  \n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 14s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RT3VHf4aU2kI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_train = len(x_train)\n",
        "x_val = x_train[int(0.8*n_train):n_train]\n",
        "y_val = y_train[int(0.8*n_train):n_train]\n",
        "x_train = x_train[:int(0.8*n_train)]\n",
        "y_train = y_train[:int(0.8*n_train)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XW2GENdIU4wp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train_norm = x_train/255\n",
        "x_val_norm = x_val/255\n",
        "x_test_norm = x_test/255\n",
        "\n",
        "num_classes = len(label_names)\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_MLVHX6mU7FL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "15e77771-f077-4399-e14f-212dff25035f"
      },
      "cell_type": "code",
      "source": [
        "model_1_c = Sequential()\n",
        "model_1_c.add(Conv2D(64, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
        "model_1_c.add(Activation('relu'))\n",
        "model_1_c.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_1_c.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model_1_c.add(Activation('relu'))\n",
        "model_1_c.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_1_c.add(Flatten())\n",
        "model_1_c.add(Dense(512))\n",
        "model_1_c.add(Activation('relu'))\n",
        "model_1_c.add(Dense(10))\n",
        "model_1_c.add(Activation('softmax'))\n",
        "model_1_c.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               2097664   \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 2,141,514\n",
            "Trainable params: 2,141,514\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CsXEQ2FNU84l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        },
        "outputId": "1c69887c-2824-4dc5-d667-08cb71382e79"
      },
      "cell_type": "code",
      "source": [
        "def step_decay(epoch):\n",
        "    initial_lrate = 0.001\n",
        "    lrate = initial_lrate * math.pow(0.5, math.floor((epoch)/10))\n",
        "    lrate = max(lrate,0.00001)\n",
        "    return lrate\n",
        "opt = SGD(lr=0.0, momentum=0.9, decay=0.0)\n",
        "lrate = LearningRateScheduler(step_decay)\n",
        "batch_size = 1000\n",
        "epochs = 25\n",
        "model_1_c.compile(loss=\"categorical_crossentropy\" , optimizer=opt )\n",
        "model_1_c.fit(x_train_norm, y_train,batch_size=batch_size,epochs=epochs, validation_data=(x_val_norm,y_val), shuffle=True, callbacks=[lrate])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/25\n",
            "40000/40000 [==============================] - 9s 231us/step - loss: 2.3025 - val_loss: 2.2888\n",
            "Epoch 2/25\n",
            "40000/40000 [==============================] - 5s 122us/step - loss: 2.2809 - val_loss: 2.2713\n",
            "Epoch 3/25\n",
            "40000/40000 [==============================] - 5s 122us/step - loss: 2.2622 - val_loss: 2.2502\n",
            "Epoch 4/25\n",
            "40000/40000 [==============================] - 5s 121us/step - loss: 2.2375 - val_loss: 2.2206\n",
            "Epoch 5/25\n",
            "40000/40000 [==============================] - 5s 122us/step - loss: 2.2020 - val_loss: 2.1785\n",
            "Epoch 6/25\n",
            "40000/40000 [==============================] - 5s 122us/step - loss: 2.1528 - val_loss: 2.1240\n",
            "Epoch 7/25\n",
            "40000/40000 [==============================] - 5s 121us/step - loss: 2.0949 - val_loss: 2.0662\n",
            "Epoch 8/25\n",
            "40000/40000 [==============================] - 5s 122us/step - loss: 2.0408 - val_loss: 2.0207\n",
            "Epoch 9/25\n",
            "40000/40000 [==============================] - 5s 123us/step - loss: 1.9991 - val_loss: 1.9866\n",
            "Epoch 10/25\n",
            "40000/40000 [==============================] - 5s 122us/step - loss: 1.9687 - val_loss: 1.9618\n",
            "Epoch 11/25\n",
            "40000/40000 [==============================] - 5s 121us/step - loss: 1.9481 - val_loss: 1.9489\n",
            "Epoch 12/25\n",
            "40000/40000 [==============================] - 5s 121us/step - loss: 1.9371 - val_loss: 1.9402\n",
            "Epoch 13/25\n",
            "40000/40000 [==============================] - 5s 122us/step - loss: 1.9276 - val_loss: 1.9307\n",
            "Epoch 14/25\n",
            "40000/40000 [==============================] - 5s 122us/step - loss: 1.9185 - val_loss: 1.9229\n",
            "Epoch 15/25\n",
            "40000/40000 [==============================] - 5s 122us/step - loss: 1.9101 - val_loss: 1.9148\n",
            "Epoch 16/25\n",
            "40000/40000 [==============================] - 5s 121us/step - loss: 1.9018 - val_loss: 1.9079\n",
            "Epoch 17/25\n",
            "40000/40000 [==============================] - 5s 122us/step - loss: 1.8930 - val_loss: 1.8993\n",
            "Epoch 18/25\n",
            "40000/40000 [==============================] - 5s 122us/step - loss: 1.8856 - val_loss: 1.8918\n",
            "Epoch 19/25\n",
            "40000/40000 [==============================] - 5s 122us/step - loss: 1.8772 - val_loss: 1.8840\n",
            "Epoch 20/25\n",
            "40000/40000 [==============================] - 5s 121us/step - loss: 1.8690 - val_loss: 1.8766\n",
            "Epoch 21/25\n",
            "40000/40000 [==============================] - 5s 121us/step - loss: 1.8617 - val_loss: 1.8719\n",
            "Epoch 22/25\n",
            "40000/40000 [==============================] - 5s 122us/step - loss: 1.8575 - val_loss: 1.8694\n",
            "Epoch 23/25\n",
            "40000/40000 [==============================] - 5s 121us/step - loss: 1.8535 - val_loss: 1.8630\n",
            "Epoch 24/25\n",
            "40000/40000 [==============================] - 5s 121us/step - loss: 1.8491 - val_loss: 1.8598\n",
            "Epoch 25/25\n",
            "40000/40000 [==============================] - 5s 122us/step - loss: 1.8451 - val_loss: 1.8564\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f25f093c2e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "nzeZKqX1VBG8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5349
        },
        "outputId": "eb9ead4c-7cd1-4cbf-acdd-242e94e52443"
      },
      "cell_type": "code",
      "source": [
        "x_train_norm"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.23137255, 0.24313725, 0.24705882],\n",
              "         [0.16862745, 0.18039216, 0.17647059],\n",
              "         [0.19607843, 0.18823529, 0.16862745],\n",
              "         ...,\n",
              "         [0.61960784, 0.51764706, 0.42352941],\n",
              "         [0.59607843, 0.49019608, 0.4       ],\n",
              "         [0.58039216, 0.48627451, 0.40392157]],\n",
              "\n",
              "        [[0.0627451 , 0.07843137, 0.07843137],\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         [0.07058824, 0.03137255, 0.        ],\n",
              "         ...,\n",
              "         [0.48235294, 0.34509804, 0.21568627],\n",
              "         [0.46666667, 0.3254902 , 0.19607843],\n",
              "         [0.47843137, 0.34117647, 0.22352941]],\n",
              "\n",
              "        [[0.09803922, 0.09411765, 0.08235294],\n",
              "         [0.0627451 , 0.02745098, 0.        ],\n",
              "         [0.19215686, 0.10588235, 0.03137255],\n",
              "         ...,\n",
              "         [0.4627451 , 0.32941176, 0.19607843],\n",
              "         [0.47058824, 0.32941176, 0.19607843],\n",
              "         [0.42745098, 0.28627451, 0.16470588]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.81568627, 0.66666667, 0.37647059],\n",
              "         [0.78823529, 0.6       , 0.13333333],\n",
              "         [0.77647059, 0.63137255, 0.10196078],\n",
              "         ...,\n",
              "         [0.62745098, 0.52156863, 0.2745098 ],\n",
              "         [0.21960784, 0.12156863, 0.02745098],\n",
              "         [0.20784314, 0.13333333, 0.07843137]],\n",
              "\n",
              "        [[0.70588235, 0.54509804, 0.37647059],\n",
              "         [0.67843137, 0.48235294, 0.16470588],\n",
              "         [0.72941176, 0.56470588, 0.11764706],\n",
              "         ...,\n",
              "         [0.72156863, 0.58039216, 0.36862745],\n",
              "         [0.38039216, 0.24313725, 0.13333333],\n",
              "         [0.3254902 , 0.20784314, 0.13333333]],\n",
              "\n",
              "        [[0.69411765, 0.56470588, 0.45490196],\n",
              "         [0.65882353, 0.50588235, 0.36862745],\n",
              "         [0.70196078, 0.55686275, 0.34117647],\n",
              "         ...,\n",
              "         [0.84705882, 0.72156863, 0.54901961],\n",
              "         [0.59215686, 0.4627451 , 0.32941176],\n",
              "         [0.48235294, 0.36078431, 0.28235294]]],\n",
              "\n",
              "\n",
              "       [[[0.60392157, 0.69411765, 0.73333333],\n",
              "         [0.49411765, 0.5372549 , 0.53333333],\n",
              "         [0.41176471, 0.40784314, 0.37254902],\n",
              "         ...,\n",
              "         [0.35686275, 0.37254902, 0.27843137],\n",
              "         [0.34117647, 0.35294118, 0.27843137],\n",
              "         [0.30980392, 0.31764706, 0.2745098 ]],\n",
              "\n",
              "        [[0.54901961, 0.62745098, 0.6627451 ],\n",
              "         [0.56862745, 0.6       , 0.60392157],\n",
              "         [0.49019608, 0.49019608, 0.4627451 ],\n",
              "         ...,\n",
              "         [0.37647059, 0.38823529, 0.30588235],\n",
              "         [0.30196078, 0.31372549, 0.24313725],\n",
              "         [0.27843137, 0.28627451, 0.23921569]],\n",
              "\n",
              "        [[0.54901961, 0.60784314, 0.64313725],\n",
              "         [0.54509804, 0.57254902, 0.58431373],\n",
              "         [0.45098039, 0.45098039, 0.43921569],\n",
              "         ...,\n",
              "         [0.30980392, 0.32156863, 0.25098039],\n",
              "         [0.26666667, 0.2745098 , 0.21568627],\n",
              "         [0.2627451 , 0.27058824, 0.21568627]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.68627451, 0.65490196, 0.65098039],\n",
              "         [0.61176471, 0.60392157, 0.62745098],\n",
              "         [0.60392157, 0.62745098, 0.66666667],\n",
              "         ...,\n",
              "         [0.16470588, 0.13333333, 0.14117647],\n",
              "         [0.23921569, 0.20784314, 0.22352941],\n",
              "         [0.36470588, 0.3254902 , 0.35686275]],\n",
              "\n",
              "        [[0.64705882, 0.60392157, 0.50196078],\n",
              "         [0.61176471, 0.59607843, 0.50980392],\n",
              "         [0.62352941, 0.63137255, 0.55686275],\n",
              "         ...,\n",
              "         [0.40392157, 0.36470588, 0.37647059],\n",
              "         [0.48235294, 0.44705882, 0.47058824],\n",
              "         [0.51372549, 0.4745098 , 0.51372549]],\n",
              "\n",
              "        [[0.63921569, 0.58039216, 0.47058824],\n",
              "         [0.61960784, 0.58039216, 0.47843137],\n",
              "         [0.63921569, 0.61176471, 0.52156863],\n",
              "         ...,\n",
              "         [0.56078431, 0.52156863, 0.54509804],\n",
              "         [0.56078431, 0.5254902 , 0.55686275],\n",
              "         [0.56078431, 0.52156863, 0.56470588]]],\n",
              "\n",
              "\n",
              "       [[[1.        , 1.        , 1.        ],\n",
              "         [0.99215686, 0.99215686, 0.99215686],\n",
              "         [0.99215686, 0.99215686, 0.99215686],\n",
              "         ...,\n",
              "         [0.99215686, 0.99215686, 0.99215686],\n",
              "         [0.99215686, 0.99215686, 0.99215686],\n",
              "         [0.99215686, 0.99215686, 0.99215686]],\n",
              "\n",
              "        [[1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         ...,\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ]],\n",
              "\n",
              "        [[1.        , 1.        , 1.        ],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         ...,\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.44313725, 0.47058824, 0.43921569],\n",
              "         [0.43529412, 0.4627451 , 0.43529412],\n",
              "         [0.41176471, 0.43921569, 0.41568627],\n",
              "         ...,\n",
              "         [0.28235294, 0.31764706, 0.31372549],\n",
              "         [0.28235294, 0.31372549, 0.30980392],\n",
              "         [0.28235294, 0.31372549, 0.30980392]],\n",
              "\n",
              "        [[0.43529412, 0.4627451 , 0.43137255],\n",
              "         [0.40784314, 0.43529412, 0.40784314],\n",
              "         [0.38823529, 0.41568627, 0.38431373],\n",
              "         ...,\n",
              "         [0.26666667, 0.29411765, 0.28627451],\n",
              "         [0.2745098 , 0.29803922, 0.29411765],\n",
              "         [0.30588235, 0.32941176, 0.32156863]],\n",
              "\n",
              "        [[0.41568627, 0.44313725, 0.41176471],\n",
              "         [0.38823529, 0.41568627, 0.38431373],\n",
              "         [0.37254902, 0.4       , 0.36862745],\n",
              "         ...,\n",
              "         [0.30588235, 0.33333333, 0.3254902 ],\n",
              "         [0.30980392, 0.33333333, 0.3254902 ],\n",
              "         [0.31372549, 0.3372549 , 0.32941176]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.65490196, 0.55294118, 0.43137255],\n",
              "         [0.64313725, 0.5254902 , 0.39607843],\n",
              "         [0.59215686, 0.44705882, 0.34901961],\n",
              "         ...,\n",
              "         [0.40784314, 0.27843137, 0.24705882],\n",
              "         [0.59215686, 0.41176471, 0.38823529],\n",
              "         [0.46666667, 0.30980392, 0.27058824]],\n",
              "\n",
              "        [[0.75294118, 0.64705882, 0.49803922],\n",
              "         [0.80784314, 0.63137255, 0.49019608],\n",
              "         [0.83529412, 0.58823529, 0.49019608],\n",
              "         ...,\n",
              "         [0.37647059, 0.24313725, 0.20392157],\n",
              "         [0.52941176, 0.35294118, 0.31764706],\n",
              "         [0.48235294, 0.32156863, 0.28235294]],\n",
              "\n",
              "        [[0.82352941, 0.64705882, 0.50980392],\n",
              "         [0.69803922, 0.49411765, 0.36078431],\n",
              "         [0.82352941, 0.58823529, 0.47058824],\n",
              "         ...,\n",
              "         [0.34117647, 0.20392157, 0.15686275],\n",
              "         [0.44705882, 0.28627451, 0.23529412],\n",
              "         [0.5372549 , 0.36862745, 0.32941176]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.63529412, 0.48235294, 0.45882353],\n",
              "         [0.60392157, 0.45098039, 0.43529412],\n",
              "         [0.6       , 0.44705882, 0.42745098],\n",
              "         ...,\n",
              "         [0.57254902, 0.45098039, 0.43921569],\n",
              "         [0.55686275, 0.43921569, 0.42745098],\n",
              "         [0.5254902 , 0.41568627, 0.4       ]],\n",
              "\n",
              "        [[0.62745098, 0.47843137, 0.47058824],\n",
              "         [0.61176471, 0.46666667, 0.45490196],\n",
              "         [0.61176471, 0.46666667, 0.44313725],\n",
              "         ...,\n",
              "         [0.57647059, 0.4627451 , 0.44705882],\n",
              "         [0.58823529, 0.4745098 , 0.45882353],\n",
              "         [0.56078431, 0.44705882, 0.43137255]],\n",
              "\n",
              "        [[0.61176471, 0.47058824, 0.4745098 ],\n",
              "         [0.56862745, 0.43529412, 0.42352941],\n",
              "         [0.58431373, 0.45490196, 0.42745098],\n",
              "         ...,\n",
              "         [0.64313725, 0.53333333, 0.51764706],\n",
              "         [0.68235294, 0.57254902, 0.55686275],\n",
              "         [0.63137255, 0.5254902 , 0.50980392]]],\n",
              "\n",
              "\n",
              "       [[[0.17647059, 0.29803922, 0.49803922],\n",
              "         [0.18039216, 0.30588235, 0.50980392],\n",
              "         [0.18039216, 0.31372549, 0.52156863],\n",
              "         ...,\n",
              "         [0.18823529, 0.3254902 , 0.54509804],\n",
              "         [0.18823529, 0.31764706, 0.53333333],\n",
              "         [0.18431373, 0.30588235, 0.52156863]],\n",
              "\n",
              "        [[0.18039216, 0.30588235, 0.50980392],\n",
              "         [0.18431373, 0.31372549, 0.52156863],\n",
              "         [0.18431373, 0.32156863, 0.5372549 ],\n",
              "         ...,\n",
              "         [0.2       , 0.3254902 , 0.54509804],\n",
              "         [0.19607843, 0.3254902 , 0.54509804],\n",
              "         [0.18431373, 0.32156863, 0.54117647]],\n",
              "\n",
              "        [[0.18039216, 0.31372549, 0.52156863],\n",
              "         [0.18431373, 0.32156863, 0.5372549 ],\n",
              "         [0.18431373, 0.32941176, 0.55294118],\n",
              "         ...,\n",
              "         [0.19607843, 0.3254902 , 0.54117647],\n",
              "         [0.2       , 0.3372549 , 0.56078431],\n",
              "         [0.18823529, 0.32941176, 0.56470588]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.37647059, 0.3254902 , 0.30196078],\n",
              "         [0.23529412, 0.21176471, 0.16862745],\n",
              "         [0.19607843, 0.1372549 , 0.08235294],\n",
              "         ...,\n",
              "         [0.10588235, 0.22352941, 0.07058824],\n",
              "         [0.25882353, 0.25098039, 0.09411765],\n",
              "         [0.48627451, 0.24705882, 0.15686275]],\n",
              "\n",
              "        [[0.15294118, 0.14901961, 0.1254902 ],\n",
              "         [0.15294118, 0.1372549 , 0.08235294],\n",
              "         [0.31372549, 0.22745098, 0.12941176],\n",
              "         ...,\n",
              "         [0.16470588, 0.22745098, 0.10980392],\n",
              "         [0.30196078, 0.25490196, 0.11764706],\n",
              "         [0.41176471, 0.27058824, 0.15686275]],\n",
              "\n",
              "        [[0.12156863, 0.23137255, 0.09019608],\n",
              "         [0.16862745, 0.23529412, 0.12156863],\n",
              "         [0.23921569, 0.23529412, 0.13333333],\n",
              "         ...,\n",
              "         [0.19215686, 0.20784314, 0.11764706],\n",
              "         [0.29803922, 0.24705882, 0.13333333],\n",
              "         [0.24313725, 0.20784314, 0.09411765]]],\n",
              "\n",
              "\n",
              "       [[[0.92156863, 0.98823529, 0.98823529],\n",
              "         [0.9372549 , 0.98431373, 0.98431373],\n",
              "         [0.9372549 , 0.98431373, 0.98431373],\n",
              "         ...,\n",
              "         [0.88235294, 0.98431373, 0.98823529],\n",
              "         [0.89411765, 0.98431373, 0.98823529],\n",
              "         [0.89411765, 0.98823529, 0.98823529]],\n",
              "\n",
              "        [[0.97647059, 1.        , 1.        ],\n",
              "         [0.98431373, 0.99215686, 1.        ],\n",
              "         [0.98823529, 0.99607843, 1.        ],\n",
              "         ...,\n",
              "         [0.89803922, 1.        , 1.        ],\n",
              "         [0.90588235, 1.        , 1.        ],\n",
              "         [0.90980392, 1.        , 1.        ]],\n",
              "\n",
              "        [[0.94509804, 0.98039216, 0.99607843],\n",
              "         [0.95294118, 0.97254902, 0.98823529],\n",
              "         [0.96078431, 0.97254902, 0.98823529],\n",
              "         ...,\n",
              "         [0.90588235, 0.99215686, 0.98431373],\n",
              "         [0.90980392, 0.99215686, 0.98823529],\n",
              "         [0.91372549, 0.99215686, 0.98823529]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.31764706, 0.4627451 , 0.69019608],\n",
              "         [0.33333333, 0.48235294, 0.69803922],\n",
              "         [0.3254902 , 0.48235294, 0.68627451],\n",
              "         ...,\n",
              "         [0.65490196, 0.65490196, 0.65882353],\n",
              "         [0.65882353, 0.65882353, 0.66666667],\n",
              "         [0.64705882, 0.65098039, 0.6627451 ]],\n",
              "\n",
              "        [[0.30980392, 0.46666667, 0.69019608],\n",
              "         [0.27058824, 0.42352941, 0.63921569],\n",
              "         [0.2627451 , 0.41176471, 0.61960784],\n",
              "         ...,\n",
              "         [0.66666667, 0.6745098 , 0.68235294],\n",
              "         [0.63921569, 0.64313725, 0.65490196],\n",
              "         [0.63137255, 0.64313725, 0.6627451 ]],\n",
              "\n",
              "        [[0.18039216, 0.34117647, 0.55686275],\n",
              "         [0.17647059, 0.3254902 , 0.5372549 ],\n",
              "         [0.20392157, 0.34509804, 0.55294118],\n",
              "         ...,\n",
              "         [0.68627451, 0.70196078, 0.71372549],\n",
              "         [0.65882353, 0.6745098 , 0.68627451],\n",
              "         [0.63921569, 0.6627451 , 0.68235294]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "BjuMz7QvXr99",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}