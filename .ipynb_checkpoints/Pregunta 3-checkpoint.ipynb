{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF-395 Redes Neuronales Artificiales\n",
    "## Tarea 1 - Redes Neuronales\n",
    "\n",
    "### Integrantes:\n",
    "* Ignacio Valenzuela Albornoz 2014073055-1\n",
    "* Rodrigo González Smith 201303026-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desarrollo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de proceder a realizar el trabajo importamos las librerías y paquetes que usaremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ipresnya/aidPython/lib64/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.callbacks import TerminateOnNaN\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dropout\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.optimizers import SGD, Adam, RMSprop, Adagrad, Adadelta\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entendimiento de imágenes de personas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3.a. Importar datos\n",
    "\n",
    "Importamos los dataset de entrenamiento y de pruebas con extension mat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "mat_train = sio.loadmat(\"AgeGenderClassification/eventrain.mat\")\n",
    "mat_test = sio.loadmat(\"AgeGenderClassification/eventest.mat\")\n",
    "data_train= mat_train[\"trcoll\"][0][0]\n",
    "data_test= mat_test[\"tecoll\"][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable data_train y data_test contienen todos los datos necesarios, donde vemos que poseen 11 atributos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7153\n",
      "4703\n"
     ]
    }
   ],
   "source": [
    "contador = 0\n",
    "for i in range(0,11):\n",
    "    contador += len(data_train[i][0])\n",
    "print(contador)\n",
    "\n",
    "contador = 0\n",
    "for i in range(0,11):\n",
    "    contador += len(data_test[i][0])\n",
    "print(contador)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que data_train posee una cantidad de 3500x7153 datos, mientras que el conjunto de test posee 1050x4703."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.b Eleccion de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero que todo escogeremos los atributos mas relevantes del dataset, los cuales son asignados abajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "genFeat = data_train[0]  #it can be used as representation: contextual features\n",
    "ageClass = data_train[1] #target\n",
    "ffcoefs = data_train[3]   #it can be used as representation: fisherface space\n",
    "faceGist = data_train[4] #\n",
    "\n",
    "genFeatTest = data_test[0]  #it can be used as representation: contextual features\n",
    "ageClassTest = data_test[1] #target\n",
    "ffcoefsTest = data_test[3]   #it can be used as representation: fisherface space\n",
    "faceGistTest = data_test[4] #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describiendo estos atributos:\n",
    "\n",
    "    genFeat: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.concatenate((genFeat,ffcoefs,faceGist),axis=1))\n",
    "dataTest = pd.DataFrame(np.concatenate((genFeatTest,ffcoefsTest,faceGistTest),axis=1))\n",
    "target = pd.DataFrame(ageClass)\n",
    "targetTest = pd.DataFrame(ageClassTest)\n",
    "scaler = StandardScaler().fit(data)\n",
    "X_scaled = pd.DataFrame(scaler.transform(data),columns=data.columns)\n",
    "\n",
    "scaler = StandardScaler().fit(dataTest)\n",
    "X_scaled_test = pd.DataFrame(scaler.transform(dataTest), columns = dataTest.columns)\n",
    "\n",
    "df_train=X_scaled[:int(0.6*len(X_scaled))]                       #60% de los datos\n",
    "df_val=X_scaled[int(0.6*len(X_scaled))::]\n",
    "y_train = target[:int(0.6*len(target))]\n",
    "y_val = target[int(0.6*len(target))::]\n",
    "\n",
    "df_train = np.matrix(df_train)\n",
    "y_train = np.matrix(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2100 samples, validate on 1400 samples\n",
      "Epoch 1/250\n",
      "2100/2100 [==============================] - 2s 811us/step - loss: 574.5261 - val_loss: 606.3644\n",
      "Epoch 2/250\n",
      "2100/2100 [==============================] - 2s 745us/step - loss: 381.6054 - val_loss: 404.2712\n",
      "Epoch 3/250\n",
      "2100/2100 [==============================] - 1s 709us/step - loss: 316.0910 - val_loss: 377.9735\n",
      "Epoch 4/250\n",
      "2100/2100 [==============================] - 1s 711us/step - loss: 295.0091 - val_loss: 347.2819\n",
      "Epoch 5/250\n",
      "2100/2100 [==============================] - 2s 744us/step - loss: 274.5120 - val_loss: 382.3504\n",
      "Epoch 6/250\n",
      "2100/2100 [==============================] - 1s 714us/step - loss: 263.2636 - val_loss: 330.3215\n",
      "Epoch 7/250\n",
      "2100/2100 [==============================] - 1s 712us/step - loss: 251.9703 - val_loss: 288.0116\n",
      "Epoch 8/250\n",
      "2100/2100 [==============================] - 2s 747us/step - loss: 237.7920 - val_loss: 331.2261\n",
      "Epoch 9/250\n",
      "2100/2100 [==============================] - 2s 738us/step - loss: 232.2423 - val_loss: 314.9896\n",
      "Epoch 10/250\n",
      "2100/2100 [==============================] - 2s 733us/step - loss: 217.8251 - val_loss: 317.0837\n",
      "Epoch 11/250\n",
      "2100/2100 [==============================] - 2s 715us/step - loss: 212.6584 - val_loss: 280.7475\n",
      "Epoch 12/250\n",
      "2100/2100 [==============================] - 2s 725us/step - loss: 203.2358 - val_loss: 313.9616\n",
      "Epoch 13/250\n",
      "2100/2100 [==============================] - 2s 723us/step - loss: 197.1813 - val_loss: 300.3197\n",
      "Epoch 14/250\n",
      "2100/2100 [==============================] - 2s 715us/step - loss: 188.9158 - val_loss: 315.4042\n",
      "Epoch 15/250\n",
      "2100/2100 [==============================] - 1s 714us/step - loss: 183.3182 - val_loss: 300.3350\n",
      "Epoch 16/250\n",
      "2100/2100 [==============================] - 2s 720us/step - loss: 176.6418 - val_loss: 304.0126\n",
      "Epoch 17/250\n",
      "2100/2100 [==============================] - 2s 728us/step - loss: 169.4506 - val_loss: 284.0212\n",
      "Epoch 18/250\n",
      "2100/2100 [==============================] - 2s 724us/step - loss: 164.6624 - val_loss: 274.3829\n",
      "Epoch 19/250\n",
      "2100/2100 [==============================] - 2s 715us/step - loss: 156.7843 - val_loss: 302.8562\n",
      "Epoch 20/250\n",
      "2100/2100 [==============================] - 2s 724us/step - loss: 151.2203 - val_loss: 281.0829\n",
      "Epoch 21/250\n",
      "2100/2100 [==============================] - 2s 733us/step - loss: 150.7033 - val_loss: 289.8591\n",
      "Epoch 22/250\n",
      "2100/2100 [==============================] - 2s 715us/step - loss: 142.9951 - val_loss: 266.4539\n",
      "Epoch 23/250\n",
      "2100/2100 [==============================] - 2s 718us/step - loss: 139.4731 - val_loss: 266.1486\n",
      "Epoch 24/250\n",
      "2100/2100 [==============================] - 2s 754us/step - loss: 135.6552 - val_loss: 267.0501\n",
      "Epoch 25/250\n",
      "2100/2100 [==============================] - 2s 732us/step - loss: 132.8636 - val_loss: 277.9916\n",
      "Epoch 26/250\n",
      "2100/2100 [==============================] - 2s 727us/step - loss: 128.1020 - val_loss: 282.1588\n",
      "Epoch 27/250\n",
      "2100/2100 [==============================] - 2s 769us/step - loss: 124.2662 - val_loss: 281.9768\n",
      "Epoch 28/250\n",
      "2100/2100 [==============================] - 2s 748us/step - loss: 122.3031 - val_loss: 294.8843\n",
      "Epoch 29/250\n",
      "2100/2100 [==============================] - 2s 744us/step - loss: 117.0495 - val_loss: 282.5519\n",
      "Epoch 30/250\n",
      "2100/2100 [==============================] - 2s 741us/step - loss: 116.7214 - val_loss: 285.5094\n",
      "Epoch 31/250\n",
      "2100/2100 [==============================] - 2s 749us/step - loss: 109.9571 - val_loss: 267.2339\n",
      "Epoch 32/250\n",
      "2100/2100 [==============================] - 2s 758us/step - loss: 109.4789 - val_loss: 275.4751\n",
      "Epoch 33/250\n",
      "2100/2100 [==============================] - 2s 756us/step - loss: 107.5965 - val_loss: 283.1979\n",
      "Epoch 34/250\n",
      "2100/2100 [==============================] - 2s 767us/step - loss: 106.5549 - val_loss: 285.8648\n",
      "Epoch 35/250\n",
      "2100/2100 [==============================] - 2s 773us/step - loss: 104.0332 - val_loss: 292.6619\n",
      "Epoch 36/250\n",
      "2100/2100 [==============================] - 2s 777us/step - loss: 101.7892 - val_loss: 287.5044\n",
      "Epoch 37/250\n",
      "2100/2100 [==============================] - 2s 783us/step - loss: 98.5244 - val_loss: 286.1396\n",
      "Epoch 38/250\n",
      "2100/2100 [==============================] - 2s 777us/step - loss: 98.4698 - val_loss: 282.4064\n",
      "Epoch 39/250\n",
      "2100/2100 [==============================] - 2s 786us/step - loss: 95.2630 - val_loss: 283.5521\n",
      "Epoch 40/250\n",
      "2100/2100 [==============================] - 2s 772us/step - loss: 93.0536 - val_loss: 289.3782\n",
      "Epoch 41/250\n",
      "2100/2100 [==============================] - 2s 785us/step - loss: 93.0073 - val_loss: 287.4738\n",
      "Epoch 42/250\n",
      "2100/2100 [==============================] - 2s 791us/step - loss: 90.9427 - val_loss: 286.1443\n",
      "Epoch 43/250\n",
      "2100/2100 [==============================] - 2s 785us/step - loss: 90.2433 - val_loss: 290.3067\n",
      "Epoch 44/250\n",
      "2100/2100 [==============================] - 2s 794us/step - loss: 84.3466 - val_loss: 278.7583\n",
      "Epoch 45/250\n",
      "2100/2100 [==============================] - 2s 800us/step - loss: 90.6871 - val_loss: 283.7402\n",
      "Epoch 46/250\n",
      "2100/2100 [==============================] - 2s 798us/step - loss: 85.0377 - val_loss: 283.7749\n",
      "Epoch 47/250\n",
      "2100/2100 [==============================] - 2s 814us/step - loss: 84.4310 - val_loss: 291.2459\n",
      "Epoch 48/250\n",
      "2100/2100 [==============================] - 2s 798us/step - loss: 78.4897 - val_loss: 271.8821\n",
      "Epoch 49/250\n",
      "2100/2100 [==============================] - 2s 804us/step - loss: 83.1825 - val_loss: 281.7996\n",
      "Epoch 50/250\n",
      "2100/2100 [==============================] - 2s 807us/step - loss: 83.8661 - val_loss: 290.6741\n",
      "Epoch 51/250\n",
      "2100/2100 [==============================] - 2s 818us/step - loss: 79.3933 - val_loss: 289.7817\n",
      "Epoch 52/250\n",
      "2100/2100 [==============================] - 2s 812us/step - loss: 78.5070 - val_loss: 288.5695\n",
      "Epoch 53/250\n",
      "2100/2100 [==============================] - 2s 807us/step - loss: 77.5000 - val_loss: 281.5746\n",
      "Epoch 54/250\n",
      "2100/2100 [==============================] - 2s 824us/step - loss: 78.8610 - val_loss: 281.5748\n",
      "Epoch 55/250\n",
      "2100/2100 [==============================] - 2s 820us/step - loss: 72.4153 - val_loss: 283.6173\n",
      "Epoch 56/250\n",
      "2100/2100 [==============================] - 2s 811us/step - loss: 73.2591 - val_loss: 279.8498\n",
      "Epoch 57/250\n",
      "2100/2100 [==============================] - 2s 810us/step - loss: 71.8891 - val_loss: 281.7755\n",
      "Epoch 58/250\n",
      "2100/2100 [==============================] - 2s 820us/step - loss: 73.2826 - val_loss: 276.8458\n",
      "Epoch 59/250\n",
      "2100/2100 [==============================] - 2s 823us/step - loss: 74.5843 - val_loss: 284.9612\n",
      "Epoch 60/250\n",
      "2100/2100 [==============================] - 2s 819us/step - loss: 71.6921 - val_loss: 283.7703\n",
      "Epoch 61/250\n",
      "2100/2100 [==============================] - 2s 838us/step - loss: 70.9929 - val_loss: 288.0619\n",
      "Epoch 62/250\n",
      "2100/2100 [==============================] - 2s 826us/step - loss: 67.9370 - val_loss: 290.1477\n",
      "Epoch 63/250\n",
      "2100/2100 [==============================] - 2s 859us/step - loss: 67.8880 - val_loss: 281.7745\n",
      "Epoch 64/250\n",
      "2100/2100 [==============================] - 2s 831us/step - loss: 67.1221 - val_loss: 285.2612\n",
      "Epoch 65/250\n",
      "2100/2100 [==============================] - 2s 833us/step - loss: 68.9517 - val_loss: 281.1017\n",
      "Epoch 66/250\n",
      "2100/2100 [==============================] - 2s 828us/step - loss: 66.9759 - val_loss: 286.8500\n",
      "Epoch 67/250\n",
      "2100/2100 [==============================] - 2s 819us/step - loss: 65.2041 - val_loss: 290.8329\n",
      "Epoch 68/250\n",
      "2100/2100 [==============================] - 2s 827us/step - loss: 66.3573 - val_loss: 282.9721\n",
      "Epoch 69/250\n",
      "2100/2100 [==============================] - 2s 837us/step - loss: 63.9604 - val_loss: 287.6211\n",
      "Epoch 70/250\n",
      "2100/2100 [==============================] - 2s 842us/step - loss: 64.0953 - val_loss: 285.5382\n",
      "Epoch 71/250\n",
      "2100/2100 [==============================] - 2s 831us/step - loss: 64.3586 - val_loss: 289.4311\n",
      "Epoch 72/250\n",
      "2100/2100 [==============================] - 2s 833us/step - loss: 62.2441 - val_loss: 291.0578\n",
      "Epoch 73/250\n",
      "2100/2100 [==============================] - 2s 843us/step - loss: 62.9050 - val_loss: 291.0488\n",
      "Epoch 74/250\n",
      "2100/2100 [==============================] - 2s 849us/step - loss: 65.2756 - val_loss: 290.7366\n",
      "Epoch 75/250\n",
      "2100/2100 [==============================] - 2s 815us/step - loss: 61.3626 - val_loss: 286.0155\n",
      "Epoch 76/250\n",
      "2100/2100 [==============================] - 2s 802us/step - loss: 62.1768 - val_loss: 284.5752\n",
      "Epoch 77/250\n",
      "2100/2100 [==============================] - 2s 804us/step - loss: 62.6856 - val_loss: 280.7325\n",
      "Epoch 78/250\n",
      "2100/2100 [==============================] - 2s 804us/step - loss: 60.8733 - val_loss: 286.6120\n",
      "Epoch 79/250\n",
      "2100/2100 [==============================] - 2s 797us/step - loss: 63.2643 - val_loss: 283.3347\n",
      "Epoch 80/250\n",
      "2100/2100 [==============================] - 2s 788us/step - loss: 60.4474 - val_loss: 282.8218\n",
      "Epoch 81/250\n",
      "2100/2100 [==============================] - 2s 795us/step - loss: 60.1548 - val_loss: 282.1561\n",
      "Epoch 82/250\n",
      "2100/2100 [==============================] - 2s 802us/step - loss: 57.2397 - val_loss: 282.6102\n",
      "Epoch 83/250\n",
      "2100/2100 [==============================] - 2s 803us/step - loss: 60.2310 - val_loss: 287.3259\n",
      "Epoch 84/250\n",
      "2100/2100 [==============================] - 2s 807us/step - loss: 58.3845 - val_loss: 281.3747\n",
      "Epoch 85/250\n",
      "2100/2100 [==============================] - 2s 810us/step - loss: 57.7498 - val_loss: 283.4410\n",
      "Epoch 86/250\n",
      "2100/2100 [==============================] - 2s 795us/step - loss: 55.3617 - val_loss: 285.8674\n",
      "Epoch 87/250\n",
      "2100/2100 [==============================] - 2s 793us/step - loss: 58.2672 - val_loss: 285.8036\n",
      "Epoch 88/250\n",
      "2100/2100 [==============================] - 2s 799us/step - loss: 59.0191 - val_loss: 281.1884\n",
      "Epoch 89/250\n",
      "2100/2100 [==============================] - 2s 801us/step - loss: 56.8071 - val_loss: 281.6404\n",
      "Epoch 90/250\n",
      "2100/2100 [==============================] - 2s 794us/step - loss: 54.4373 - val_loss: 286.2878\n",
      "Epoch 91/250\n",
      "2100/2100 [==============================] - 2s 802us/step - loss: 56.1023 - val_loss: 280.7375\n",
      "Epoch 92/250\n",
      "2100/2100 [==============================] - 2s 817us/step - loss: 54.9184 - val_loss: 283.6001\n",
      "Epoch 93/250\n",
      "2100/2100 [==============================] - 2s 808us/step - loss: 52.7610 - val_loss: 281.7496\n",
      "Epoch 94/250\n",
      "2100/2100 [==============================] - 2s 809us/step - loss: 55.7637 - val_loss: 284.4761\n",
      "Epoch 95/250\n",
      "2100/2100 [==============================] - 2s 810us/step - loss: 57.1205 - val_loss: 283.7992\n",
      "Epoch 96/250\n",
      "2100/2100 [==============================] - 2s 806us/step - loss: 52.3685 - val_loss: 285.6143\n",
      "Epoch 97/250\n",
      "2100/2100 [==============================] - 2s 808us/step - loss: 54.7389 - val_loss: 284.9969\n",
      "Epoch 98/250\n",
      "2100/2100 [==============================] - 2s 810us/step - loss: 53.6310 - val_loss: 281.5700\n",
      "Epoch 99/250\n",
      "2100/2100 [==============================] - 2s 813us/step - loss: 52.5809 - val_loss: 278.6813\n",
      "Epoch 100/250\n",
      "2100/2100 [==============================] - 2s 805us/step - loss: 51.8834 - val_loss: 284.6489\n",
      "Epoch 101/250\n",
      "2100/2100 [==============================] - 2s 806us/step - loss: 51.6317 - val_loss: 286.0168\n",
      "Epoch 102/250\n",
      "2100/2100 [==============================] - 2s 802us/step - loss: 53.5010 - val_loss: 282.4303\n",
      "Epoch 103/250\n",
      "2100/2100 [==============================] - 2s 819us/step - loss: 53.7848 - val_loss: 284.3413\n",
      "Epoch 104/250\n",
      "2100/2100 [==============================] - 2s 815us/step - loss: 53.4324 - val_loss: 281.3534\n",
      "Epoch 105/250\n",
      "2100/2100 [==============================] - 2s 811us/step - loss: 52.0416 - val_loss: 286.0427\n",
      "Epoch 106/250\n",
      "2100/2100 [==============================] - 2s 824us/step - loss: 53.0162 - val_loss: 280.2700\n",
      "Epoch 107/250\n",
      "2100/2100 [==============================] - 2s 831us/step - loss: 53.2219 - val_loss: 279.6646\n",
      "Epoch 108/250\n",
      "2100/2100 [==============================] - 2s 816us/step - loss: 51.2301 - val_loss: 286.9651\n",
      "Epoch 109/250\n",
      "2100/2100 [==============================] - 2s 839us/step - loss: 50.8165 - val_loss: 286.0131\n",
      "Epoch 110/250\n",
      "2100/2100 [==============================] - 2s 830us/step - loss: 51.9989 - val_loss: 283.7552\n",
      "Epoch 111/250\n",
      "2100/2100 [==============================] - 2s 813us/step - loss: 49.6234 - val_loss: 277.1345\n",
      "Epoch 112/250\n",
      "2100/2100 [==============================] - 2s 823us/step - loss: 51.7570 - val_loss: 282.7350\n",
      "Epoch 113/250\n",
      "2100/2100 [==============================] - 2s 825us/step - loss: 50.4373 - val_loss: 279.7921\n",
      "Epoch 114/250\n",
      "2100/2100 [==============================] - 2s 827us/step - loss: 52.2256 - val_loss: 282.2277\n",
      "Epoch 115/250\n",
      "2100/2100 [==============================] - 2s 825us/step - loss: 49.9262 - val_loss: 281.7743\n",
      "Epoch 116/250\n",
      "2100/2100 [==============================] - 2s 828us/step - loss: 47.3536 - val_loss: 284.8463\n",
      "Epoch 117/250\n",
      "2100/2100 [==============================] - 2s 826us/step - loss: 49.3759 - val_loss: 279.7709\n",
      "Epoch 118/250\n",
      "2100/2100 [==============================] - 2s 829us/step - loss: 51.0340 - val_loss: 283.8183\n",
      "Epoch 119/250\n",
      "2100/2100 [==============================] - 2s 829us/step - loss: 50.4396 - val_loss: 281.9234\n",
      "Epoch 120/250\n",
      "2100/2100 [==============================] - 2s 832us/step - loss: 50.3613 - val_loss: 286.1775\n",
      "Epoch 121/250\n",
      "2100/2100 [==============================] - 2s 834us/step - loss: 50.6680 - val_loss: 282.4748\n",
      "Epoch 122/250\n",
      "2100/2100 [==============================] - 2s 824us/step - loss: 50.9435 - val_loss: 277.5403\n",
      "Epoch 123/250\n",
      "2100/2100 [==============================] - 2s 827us/step - loss: 50.7496 - val_loss: 280.4640\n",
      "Epoch 124/250\n",
      "2100/2100 [==============================] - 2s 825us/step - loss: 49.0653 - val_loss: 281.4696\n",
      "Epoch 125/250\n",
      "2100/2100 [==============================] - 2s 830us/step - loss: 48.4888 - val_loss: 280.9343\n",
      "Epoch 126/250\n",
      "2100/2100 [==============================] - 2s 827us/step - loss: 47.2195 - val_loss: 280.8626\n",
      "Epoch 127/250\n",
      "2100/2100 [==============================] - 2s 838us/step - loss: 45.4745 - val_loss: 283.0889\n",
      "Epoch 128/250\n",
      "2100/2100 [==============================] - 2s 835us/step - loss: 48.6768 - val_loss: 277.5194\n",
      "Epoch 129/250\n",
      "2100/2100 [==============================] - 2s 829us/step - loss: 45.0215 - val_loss: 280.6250\n",
      "Epoch 130/250\n",
      "2100/2100 [==============================] - 2s 825us/step - loss: 48.5882 - val_loss: 283.7146\n",
      "Epoch 131/250\n",
      "2100/2100 [==============================] - 2s 832us/step - loss: 51.1176 - val_loss: 277.3253\n",
      "Epoch 132/250\n",
      "2100/2100 [==============================] - 2s 833us/step - loss: 48.5617 - val_loss: 281.8327\n",
      "Epoch 133/250\n",
      "2100/2100 [==============================] - 2s 830us/step - loss: 47.1262 - val_loss: 282.5030\n",
      "Epoch 134/250\n",
      "2100/2100 [==============================] - 2s 837us/step - loss: 48.2037 - val_loss: 282.2891\n",
      "Epoch 135/250\n",
      "2100/2100 [==============================] - 2s 831us/step - loss: 48.4502 - val_loss: 280.7039\n",
      "Epoch 136/250\n",
      "2100/2100 [==============================] - 2s 827us/step - loss: 46.9382 - val_loss: 284.7697\n",
      "Epoch 137/250\n",
      "2100/2100 [==============================] - 2s 830us/step - loss: 46.3849 - val_loss: 283.1155\n",
      "Epoch 138/250\n",
      "2100/2100 [==============================] - 2s 834us/step - loss: 46.7737 - val_loss: 284.1414\n",
      "Epoch 139/250\n",
      "2100/2100 [==============================] - 2s 824us/step - loss: 47.5766 - val_loss: 283.5257\n",
      "Epoch 140/250\n",
      "2100/2100 [==============================] - 2s 881us/step - loss: 45.1148 - val_loss: 279.5238\n",
      "Epoch 141/250\n",
      "2100/2100 [==============================] - 2s 944us/step - loss: 46.2270 - val_loss: 282.3027\n",
      "Epoch 142/250\n",
      "2100/2100 [==============================] - 2s 917us/step - loss: 48.7268 - val_loss: 280.3884\n",
      "Epoch 143/250\n",
      "2100/2100 [==============================] - 2s 915us/step - loss: 46.7826 - val_loss: 283.1795\n",
      "Epoch 144/250\n",
      "2100/2100 [==============================] - 2s 944us/step - loss: 48.1061 - val_loss: 281.9702\n",
      "Epoch 145/250\n",
      "2100/2100 [==============================] - 2s 913us/step - loss: 46.1119 - val_loss: 277.3066\n",
      "Epoch 146/250\n",
      "2100/2100 [==============================] - 2s 926us/step - loss: 45.4714 - val_loss: 284.4800\n",
      "Epoch 147/250\n",
      "2100/2100 [==============================] - 2s 904us/step - loss: 46.3896 - val_loss: 281.4695\n",
      "Epoch 148/250\n",
      "2100/2100 [==============================] - 2s 900us/step - loss: 46.4521 - val_loss: 280.8449\n",
      "Epoch 149/250\n",
      "2100/2100 [==============================] - 2s 932us/step - loss: 44.0126 - val_loss: 287.1388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/250\n",
      "2100/2100 [==============================] - 2s 828us/step - loss: 45.7375 - val_loss: 281.9300\n",
      "Epoch 151/250\n",
      "2100/2100 [==============================] - 2s 825us/step - loss: 43.7757 - val_loss: 281.9163\n",
      "Epoch 152/250\n",
      "2100/2100 [==============================] - 2s 825us/step - loss: 43.2479 - val_loss: 281.9654\n",
      "Epoch 153/250\n",
      "2100/2100 [==============================] - 2s 855us/step - loss: 48.2822 - val_loss: 279.7314\n",
      "Epoch 154/250\n",
      "2100/2100 [==============================] - 2s 830us/step - loss: 46.2427 - val_loss: 277.6947\n",
      "Epoch 155/250\n",
      "2100/2100 [==============================] - 2s 833us/step - loss: 46.8076 - val_loss: 279.8106\n",
      "Epoch 156/250\n",
      "2100/2100 [==============================] - 2s 841us/step - loss: 44.5926 - val_loss: 281.3795\n",
      "Epoch 157/250\n",
      "2100/2100 [==============================] - 2s 840us/step - loss: 43.5788 - val_loss: 280.4580\n",
      "Epoch 158/250\n",
      "2100/2100 [==============================] - 2s 841us/step - loss: 44.8744 - val_loss: 280.5977\n",
      "Epoch 159/250\n",
      "2100/2100 [==============================] - 2s 836us/step - loss: 47.2004 - val_loss: 281.1001\n",
      "Epoch 160/250\n",
      "2100/2100 [==============================] - 2s 835us/step - loss: 44.8029 - val_loss: 280.3612\n",
      "Epoch 161/250\n",
      "2100/2100 [==============================] - 2s 841us/step - loss: 44.1875 - val_loss: 280.0438\n",
      "Epoch 162/250\n",
      "2100/2100 [==============================] - 2s 838us/step - loss: 42.8371 - val_loss: 284.0224\n",
      "Epoch 163/250\n",
      "2100/2100 [==============================] - 2s 835us/step - loss: 46.9518 - val_loss: 281.9822\n",
      "Epoch 164/250\n",
      "2100/2100 [==============================] - 2s 848us/step - loss: 43.2900 - val_loss: 281.5510\n",
      "Epoch 165/250\n",
      "2100/2100 [==============================] - 2s 832us/step - loss: 44.8139 - val_loss: 281.1467\n",
      "Epoch 166/250\n",
      "2100/2100 [==============================] - 2s 827us/step - loss: 44.2402 - val_loss: 283.5096\n",
      "Epoch 167/250\n",
      "2100/2100 [==============================] - 2s 845us/step - loss: 42.3233 - val_loss: 284.9417\n",
      "Epoch 168/250\n",
      "2100/2100 [==============================] - 2s 855us/step - loss: 44.5734 - val_loss: 279.0027\n",
      "Epoch 169/250\n",
      "2100/2100 [==============================] - 2s 884us/step - loss: 44.2675 - val_loss: 282.6843\n",
      "Epoch 170/250\n",
      "2100/2100 [==============================] - 2s 834us/step - loss: 41.9011 - val_loss: 282.0936\n",
      "Epoch 171/250\n",
      "2100/2100 [==============================] - 2s 817us/step - loss: 44.6963 - val_loss: 280.6235\n",
      "Epoch 172/250\n",
      "2100/2100 [==============================] - 2s 859us/step - loss: 43.4798 - val_loss: 278.0437\n",
      "Epoch 173/250\n",
      "2100/2100 [==============================] - 2s 832us/step - loss: 45.1105 - val_loss: 283.0083\n",
      "Epoch 174/250\n",
      "2100/2100 [==============================] - 2s 833us/step - loss: 41.7514 - val_loss: 281.1621\n",
      "Epoch 175/250\n",
      "2100/2100 [==============================] - 2s 827us/step - loss: 43.7961 - val_loss: 278.4541\n",
      "Epoch 176/250\n",
      "2100/2100 [==============================] - 2s 826us/step - loss: 41.4107 - val_loss: 279.8983\n",
      "Epoch 177/250\n",
      "2100/2100 [==============================] - 2s 821us/step - loss: 44.2833 - val_loss: 281.7210\n",
      "Epoch 178/250\n",
      "2100/2100 [==============================] - 2s 862us/step - loss: 43.8359 - val_loss: 281.4228\n",
      "Epoch 179/250\n",
      "2100/2100 [==============================] - 2s 860us/step - loss: 40.8860 - val_loss: 278.6444\n",
      "Epoch 180/250\n",
      "2100/2100 [==============================] - 2s 886us/step - loss: 46.0851 - val_loss: 277.4594\n",
      "Epoch 181/250\n",
      "2100/2100 [==============================] - 2s 879us/step - loss: 42.3522 - val_loss: 281.2494\n",
      "Epoch 182/250\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 43.9378 - val_loss: 277.2425\n",
      "Epoch 183/250\n",
      "2100/2100 [==============================] - 2s 879us/step - loss: 43.1321 - val_loss: 282.6656\n",
      "Epoch 184/250\n",
      "2100/2100 [==============================] - 2s 917us/step - loss: 42.1959 - val_loss: 281.1410\n",
      "Epoch 185/250\n",
      "2100/2100 [==============================] - 2s 845us/step - loss: 43.2245 - val_loss: 281.9676\n",
      "Epoch 186/250\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 43.9862 - val_loss: 281.9869\n",
      "Epoch 187/250\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 42.9913 - val_loss: 281.2266\n",
      "Epoch 188/250\n",
      "2100/2100 [==============================] - 2s 958us/step - loss: 44.2003 - val_loss: 277.7538\n",
      "Epoch 189/250\n",
      "2100/2100 [==============================] - 2s 958us/step - loss: 42.7154 - val_loss: 279.7118\n",
      "Epoch 190/250\n",
      "2100/2100 [==============================] - 2s 884us/step - loss: 43.6014 - val_loss: 279.1496\n",
      "Epoch 191/250\n",
      "2100/2100 [==============================] - 2s 860us/step - loss: 44.0749 - val_loss: 280.8278\n",
      "Epoch 192/250\n",
      "2100/2100 [==============================] - 2s 859us/step - loss: 41.7774 - val_loss: 281.0724\n",
      "Epoch 193/250\n",
      "2100/2100 [==============================] - 2s 855us/step - loss: 42.3572 - val_loss: 283.9690\n",
      "Epoch 194/250\n",
      "2100/2100 [==============================] - 2s 851us/step - loss: 43.5906 - val_loss: 282.5751\n",
      "Epoch 195/250\n",
      "2100/2100 [==============================] - 2s 851us/step - loss: 42.0438 - val_loss: 280.1008\n",
      "Epoch 196/250\n",
      "2100/2100 [==============================] - 2s 854us/step - loss: 39.5195 - val_loss: 281.5028\n",
      "Epoch 197/250\n",
      "2100/2100 [==============================] - 2s 853us/step - loss: 39.9602 - val_loss: 280.7037\n",
      "Epoch 198/250\n",
      "2100/2100 [==============================] - 2s 845us/step - loss: 40.1834 - val_loss: 281.2639\n",
      "Epoch 199/250\n",
      "2100/2100 [==============================] - 2s 851us/step - loss: 43.1067 - val_loss: 281.1415\n",
      "Epoch 200/250\n",
      "2100/2100 [==============================] - 2s 849us/step - loss: 41.2888 - val_loss: 281.6493\n",
      "Epoch 201/250\n",
      "2100/2100 [==============================] - 2s 896us/step - loss: 40.1101 - val_loss: 280.7404\n",
      "Epoch 202/250\n",
      "2100/2100 [==============================] - 2s 852us/step - loss: 41.1153 - val_loss: 279.7284\n",
      "Epoch 203/250\n",
      "2100/2100 [==============================] - 2s 857us/step - loss: 41.5245 - val_loss: 279.9139\n",
      "Epoch 204/250\n",
      "2100/2100 [==============================] - 2s 891us/step - loss: 41.9970 - val_loss: 281.0257\n",
      "Epoch 205/250\n",
      "2100/2100 [==============================] - 2s 860us/step - loss: 39.2648 - val_loss: 279.7374\n",
      "Epoch 206/250\n",
      "2100/2100 [==============================] - 2s 910us/step - loss: 40.0963 - val_loss: 278.4419\n",
      "Epoch 207/250\n",
      "2100/2100 [==============================] - 2s 862us/step - loss: 41.7356 - val_loss: 280.5057\n",
      "Epoch 208/250\n",
      "2100/2100 [==============================] - 2s 851us/step - loss: 43.1751 - val_loss: 285.0979\n",
      "Epoch 209/250\n",
      "2100/2100 [==============================] - 2s 868us/step - loss: 41.0248 - val_loss: 280.9610\n",
      "Epoch 210/250\n",
      "2100/2100 [==============================] - 2s 859us/step - loss: 42.0913 - val_loss: 279.1605\n",
      "Epoch 211/250\n",
      "2100/2100 [==============================] - 2s 855us/step - loss: 39.8606 - val_loss: 281.7408\n",
      "Epoch 212/250\n",
      "2100/2100 [==============================] - 2s 876us/step - loss: 39.9757 - val_loss: 277.4457\n",
      "Epoch 213/250\n",
      "2100/2100 [==============================] - 2s 846us/step - loss: 40.9650 - val_loss: 279.7380\n",
      "Epoch 214/250\n",
      "2100/2100 [==============================] - 2s 855us/step - loss: 40.7428 - val_loss: 280.0271\n",
      "Epoch 215/250\n",
      "2100/2100 [==============================] - 2s 861us/step - loss: 41.8870 - val_loss: 279.2454\n",
      "Epoch 216/250\n",
      "2100/2100 [==============================] - 2s 861us/step - loss: 40.0471 - val_loss: 281.1639\n",
      "Epoch 217/250\n",
      "2100/2100 [==============================] - 2s 866us/step - loss: 40.1760 - val_loss: 279.5839\n",
      "Epoch 218/250\n",
      "2100/2100 [==============================] - 2s 856us/step - loss: 40.1401 - val_loss: 280.0233\n",
      "Epoch 219/250\n",
      "2100/2100 [==============================] - 2s 865us/step - loss: 42.5450 - val_loss: 282.1056\n",
      "Epoch 220/250\n",
      "2100/2100 [==============================] - 2s 883us/step - loss: 41.1231 - val_loss: 278.7858\n",
      "Epoch 221/250\n",
      "2100/2100 [==============================] - 2s 845us/step - loss: 41.1089 - val_loss: 280.6188\n",
      "Epoch 222/250\n",
      "2100/2100 [==============================] - 2s 866us/step - loss: 40.5295 - val_loss: 282.5423\n",
      "Epoch 223/250\n",
      "2100/2100 [==============================] - 2s 859us/step - loss: 39.5709 - val_loss: 280.4690\n",
      "Epoch 224/250\n",
      "2100/2100 [==============================] - 2s 946us/step - loss: 40.4026 - val_loss: 280.3419\n",
      "Epoch 225/250\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 40.2914 - val_loss: 279.4963\n",
      "Epoch 226/250\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 39.3931 - val_loss: 279.4371\n",
      "Epoch 227/250\n",
      "2100/2100 [==============================] - 2s 892us/step - loss: 40.9582 - val_loss: 279.1029\n",
      "Epoch 228/250\n",
      "2100/2100 [==============================] - 2s 793us/step - loss: 39.3471 - val_loss: 279.6206\n",
      "Epoch 229/250\n",
      "2100/2100 [==============================] - 2s 919us/step - loss: 39.7346 - val_loss: 279.3193\n",
      "Epoch 230/250\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 37.1434 - val_loss: 280.5851\n",
      "Epoch 231/250\n",
      "2100/2100 [==============================] - 2s 833us/step - loss: 39.7034 - val_loss: 280.9213\n",
      "Epoch 232/250\n",
      "2100/2100 [==============================] - 2s 808us/step - loss: 38.5639 - val_loss: 279.2208\n",
      "Epoch 233/250\n",
      "2100/2100 [==============================] - 2s 893us/step - loss: 38.6662 - val_loss: 276.0669\n",
      "Epoch 234/250\n",
      "2100/2100 [==============================] - 2s 980us/step - loss: 38.3735 - val_loss: 279.4111\n",
      "Epoch 235/250\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 40.1974 - val_loss: 277.9055\n",
      "Epoch 236/250\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 39.3106 - val_loss: 279.6640\n",
      "Epoch 237/250\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 40.2562 - val_loss: 277.1325\n",
      "Epoch 238/250\n",
      "2100/2100 [==============================] - 2s 902us/step - loss: 39.2405 - val_loss: 281.1216\n",
      "Epoch 239/250\n",
      "2100/2100 [==============================] - 2s 880us/step - loss: 38.4274 - val_loss: 279.3015\n",
      "Epoch 240/250\n",
      "2100/2100 [==============================] - 2s 792us/step - loss: 40.9077 - val_loss: 281.3383\n",
      "Epoch 241/250\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 41.7120 - val_loss: 279.5977\n",
      "Epoch 242/250\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 39.0010 - val_loss: 280.7935\n",
      "Epoch 243/250\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 35.7304 - val_loss: 278.0843\n",
      "Epoch 244/250\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 39.3843 - val_loss: 280.0308\n",
      "Epoch 245/250\n",
      "2100/2100 [==============================] - 2s 1ms/step - loss: 38.5573 - val_loss: 280.6758\n",
      "Epoch 246/250\n",
      "2100/2100 [==============================] - 2s 947us/step - loss: 39.0943 - val_loss: 280.4237\n",
      "Epoch 247/250\n",
      "2100/2100 [==============================] - 2s 950us/step - loss: 39.0888 - val_loss: 279.4271\n",
      "Epoch 248/250\n",
      "2100/2100 [==============================] - 2s 947us/step - loss: 38.4601 - val_loss: 280.3370\n",
      "Epoch 249/250\n",
      "2100/2100 [==============================] - 2s 932us/step - loss: 37.1652 - val_loss: 280.7418\n",
      "Epoch 250/250\n",
      "2100/2100 [==============================] - 2s 947us/step - loss: 38.3804 - val_loss: 278.1442\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=df_train.shape[1], kernel_initializer='uniform',activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(400, input_dim=df_train.shape[1], kernel_initializer='uniform',activation=\"sigmoid\"))\n",
    "model.add(Dense(300, input_dim=df_train.shape[1], kernel_initializer='uniform',activation=\"sigmoid\"))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation=\"linear\"))\n",
    "model.compile(optimizer=SGD(lr=0.005, decay=0.01),loss='mean_squared_error')\n",
    "history = model.fit(df_train, y_train, epochs=250, verbose=1, batch_size=10, validation_data=(df_val, y_val), callbacks=[TerminateOnNaN()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 117us/step\n",
      "332.57063668387275\n"
     ]
    }
   ],
   "source": [
    "testito = model.evaluate(X_scaled_test, targetTest)\n",
    "print(testito)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
